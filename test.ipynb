{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import geom, multivariate_normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On fixe les paramètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_sample = 1024\n",
    "dim_x = 20\n",
    "dim_z = 20\n",
    "r = 0.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On définit les fonctions utiles au projet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_theta_x(theta):\n",
    "    mu = theta\n",
    "    covariance = 2 * np.eye(dim_x)\n",
    "    return multivariate_normal(mean=mu, cov=covariance)\n",
    "\n",
    "def p_theta_x_given_z(z):\n",
    "    mu = z\n",
    "    covariance = np.eye(dim_x)\n",
    "    return multivariate_normal(mean=mu, cov=covariance)\n",
    "\n",
    "def p_theta_z(theta):\n",
    "    mu = theta\n",
    "    covariance = np.eye(dim_z)\n",
    "    return multivariate_normal(mean=mu, cov=covariance)\n",
    "\n",
    "p = geom\n",
    "\n",
    "def logmeanexp(data, axis=None):\n",
    "    max_val = np.max(data, axis=axis)\n",
    "    return max_val + np.log(np.mean(np.exp(data - max_val), axis=axis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On simule theta et les observations. On calcule la log-vraisemblance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.26983749 -0.05577781  0.4389024   0.29475434  1.55927259  0.56357757\n",
      "  -1.11817003  1.00109145 -3.74712485  0.4779087  -0.92320417 -1.89663536\n",
      "   3.38219555 -0.02181258 -3.07432439 -0.37898559 -0.17273254 -1.76626529\n",
      "  -3.47280135  0.10789113]\n",
      " [-0.21641656 -0.76061392 -0.08936381  2.16839784 -2.19536959 -0.64158159\n",
      "  -0.51402806  1.94249372  1.43107287 -0.39061573  0.43616129  3.31729389\n",
      "  -0.53570075  0.9913435  -2.25512065  0.87710177  1.65191761 -0.84935175\n",
      "  -3.7964765  -0.81093453]]\n",
      "-35.32464786730774\n"
     ]
    }
   ],
   "source": [
    "theta_0 = multivariate_normal.rvs(mean=np.zeros(dim_x), cov=np.eye(dim_x))\n",
    "X = p_theta_x(theta_0).rvs(size=N_sample)\n",
    "print(X[:2])\n",
    "\n",
    "l_true = np.mean(np.log(p_theta_x(theta_0).pdf(X)))\n",
    "print(l_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On définit A et b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = 1 / 2 * np.eye(dim_z, dim_x) #size = dim_z, dim_x\n",
    "b = np.mean(X, axis=0) #size = dim_z, 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut donc maintenant définir l'encodeur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_phi_z_given_x(x):\n",
    "    mu = A @ x + b\n",
    "    covariance = 2 / 3 * np.eye(dim_z)\n",
    "    return multivariate_normal(mean=mu, cov=covariance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On fait tourner l'algorithme décrit dans le papier pour chaque observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_hat_ml_ss_list = []\n",
    "l_hat_ml_rr_list = []\n",
    "l_hat_iwae_list = []\n",
    "l_hat_sumo_list = []\n",
    "\n",
    "for x in X:\n",
    "    \n",
    "    K = p.rvs(r)\n",
    "    size = 2 ** (K + 1)\n",
    "    \n",
    "    Z = q_phi_z_given_x(x).rvs(size=size)\n",
    "    Z_E, Z_O = Z[::2], Z[1::2]\n",
    "    \n",
    "    log_weights = [np.log(p_theta_z(theta_0).pdf(z) * p_theta_x_given_z(z).pdf(x) / q_phi_z_given_x(x).pdf(z)) for z in Z]\n",
    "    log_weights_E, log_weights_O = log_weights[::2], log_weights[1::2]\n",
    "    \n",
    "    I_0 = np.mean(log_weights)\n",
    "    l_hat_E, l_hat_O = logmeanexp(log_weights_E), logmeanexp(log_weights_O)\n",
    "    l_hat_O_E = logmeanexp(log_weights)\n",
    "    \n",
    "    delta_K = l_hat_O_E - 0.5 * (l_hat_O + l_hat_E)\n",
    "    l_hat_ml_ss_x = I_0 + delta_K / p(r).pmf(K)\n",
    "    l_hat_ml_ss_list.append(l_hat_ml_ss_x)\n",
    "    \n",
    "    delta_k_list_rr = [logmeanexp(log_weights[:2**(k+1)]) - 0.5 * (logmeanexp(log_weights_O[:2**k]) + logmeanexp(log_weights_E[:2**k])) for k in range(K+1)]\n",
    "    l_hat_ml_rr_x = I_0 + np.sum([delta_k_list_rr[k] / (1 - p(r).cdf(k-1)) for k in range(K+1)])\n",
    "    l_hat_ml_rr_list.append(l_hat_ml_rr_x)\n",
    "\n",
    "    l_hat_iwae_list.append(logmeanexp(log_weights))\n",
    "\n",
    "    delta_k_list_sumo = [logmeanexp(log_weights[:2**(k+1)]) - logmeanexp(log_weights[:2**k]) for k in range(K+1)]\n",
    "    l_hat_sumo_x = I_0 + np.sum([delta_k_list_sumo[k] / (1 - p(r).cdf(k-1)) for k in range(K+1)])\n",
    "    l_hat_sumo_list.append(l_hat_sumo_x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On calcule les estimateurs finaux et les biais empiriques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimateur ss = -36.60740824892005\n",
      "estimateur rr = -35.527796481578264\n",
      "estimateur iwae = -36.838967459766366\n",
      "estimateur sumo = -35.181752881688894\n",
      "carré du biais empirique de l'estimateur ss : 1.6454741966341668\n",
      "carré du biais empirique de l'estimateur rr : 0.04126935948003446\n",
      "carré du biais empirique de l'estimateur iwae : 2.2931638281040607\n",
      "carré du biais empirique de l'estimateur sumo : 0.02041897691501\n"
     ]
    }
   ],
   "source": [
    "l_hat_ml_ss = np.mean(l_hat_ml_ss_list)\n",
    "print(\"estimateur ss =\", l_hat_ml_ss)\n",
    "\n",
    "l_hat_ml_rr = np.mean(l_hat_ml_rr_list)\n",
    "print(\"estimateur rr =\", l_hat_ml_rr)\n",
    "\n",
    "l_hat_iwae = np.mean(l_hat_iwae_list)\n",
    "print(\"estimateur iwae =\", l_hat_iwae)\n",
    "\n",
    "l_hat_sumo = np.mean(l_hat_sumo_list)\n",
    "print(\"estimateur sumo =\", l_hat_sumo)\n",
    "\n",
    "empirical_bias_squared_ss = (l_hat_ml_ss - l_true) ** 2\n",
    "print(\"carré du biais empirique de l'estimateur ss :\", empirical_bias_squared_ss)\n",
    "\n",
    "empirical_bias_squared_rr = (l_hat_ml_rr - l_true) ** 2\n",
    "print(\"carré du biais empirique de l'estimateur rr :\", empirical_bias_squared_rr)\n",
    "\n",
    "empirical_bias_squared_iwae = (l_hat_iwae - l_true) ** 2\n",
    "print(\"carré du biais empirique de l'estimateur iwae :\", empirical_bias_squared_iwae)\n",
    "\n",
    "empirical_bias_squared_sumo = (l_hat_sumo - l_true) ** 2\n",
    "print(\"carré du biais empirique de l'estimateur sumo :\", empirical_bias_squared_sumo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
